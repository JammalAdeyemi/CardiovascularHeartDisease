{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17acf319-6314-4f31-890e-90b79189b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, classification_report, plot_confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facbd3ef-a4fb-49e9-b8af-ad3b9d168c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  \\\n",
       "0   50       2     168      62    110     80            1     1      0     0   \n",
       "1   55       1     156      85    140     90            3     1      0     0   \n",
       "2   51       1     165      64    130     70            3     1      0     0   \n",
       "3   48       2     169      82    150    100            1     1      0     0   \n",
       "4   47       1     156      56    100     60            1     1      0     0   \n",
       "\n",
       "   active  cardio  BMI  \n",
       "0       1       0   21  \n",
       "1       1       1   34  \n",
       "2       0       1   23  \n",
       "3       1       1   28  \n",
       "4       0       0   23  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/new_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45231a5d-1a7a-4c7e-8c91-9eee4fdc6adb",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873f0ab2-dc81-48ca-90b9-4d3fa6fdcc34",
   "metadata": {},
   "source": [
    "### Train | Validation | Test Split Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0725ff50-e0cb-4427-b951-e738bd08fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('cardio', axis=1)\n",
    "y = df['cardio']\n",
    "\n",
    "# Split the data into training and testing sets. 80% of data is training data, set aside other 20% for test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Remaining 80% is split into valuation and test sets. \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the data using standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Scale the data using normalization\n",
    "normalizer = MinMaxScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_val_norm = normalizer.transform(X_val)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc342e1-c4fc-4bca-81ae-1bdee96ed9bc",
   "metadata": {},
   "source": [
    "Here, we are preparing data for use in a machine learning model that will predict whether someone has cardiovascular disease or not, based on various health-related features. Here is a breakdown of each step:\n",
    "\n",
    "1. The first line `X = df.drop('cardio', axis=1)` selects all columns from the input dataframe except for the 'cardio' column. These are the features that the machine learning model will use to make its predictions. The second line `y = df['cardio']` selects only the 'cardio' column from the input dataframe. This is the column that contains the labels or outcomes we are trying to predict.\n",
    "\n",
    "2. The third line uses the `train_test_split` function from the `sklearn library` to split the data into training and testing sets. We are using 80% of the data for training and 20% for testing. The `random_state` parameter is set to 42, which ensures that the data is split in the same way every time the code is run.\n",
    "\n",
    "3. The fourth line further splits the training data into training and validation sets. We are using a `75/25` split (60% for training, 20% for validation) to tune our model's hyperparameters later.\n",
    "\n",
    "4. The next three lines scale the data using standardization. Standardization scales the data to have a mean of 0 and a standard deviation of 1. This is useful for machine learning algorithms that assume the features are normally distributed. The `fit_transform` method fits the scaler on the training data and applies it to the training, validation, and testing data. We are overwriting the original `X_train` variable with the transformed data.\n",
    "\n",
    "5. The last three lines scale the data using normalization. Normalization scales the data to be between 0 and 1. This is useful for machine learning algorithms that are sensitive to the scale of the features. The `fit_transform` method fits the normalizer on the training data and applies it to the training, validation, and testing data. We are creating new variables `X_train_norm, X_val_norm,` and `X_test_norm` to store the transformed data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef52e8-1ae1-46b8-8a65-22014452f205",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f4531e-50b6-42d1-9e2d-81e9474cdbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put models in a dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(),\n",
    "          \"Adaboost Classifier\": AdaBoostClassifier(),\n",
    "          \"Gradientboost Classifier\": GradientBoostingClassifier(),\n",
    "          \"Random Forest\": RandomForestClassifier()}\n",
    "\n",
    "# Create a function to fit and score models\n",
    "def fit_and_score(models, X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    # Set random seed\n",
    "    np.random.seed(42)\n",
    "    # Make a dictionary to keep model scores\n",
    "    model_scores = {}\n",
    "    # Loop through models\n",
    "    for name, model in models.items():\n",
    "        # Fit the model to the training set\n",
    "        model.fit(X_train, y_train)\n",
    "        # Make predictions on the validation and test sets\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        # Calculate accuracy and precision scores on the validation and test sets\n",
    "        val_acc = accuracy_score(y_val, y_val_pred)\n",
    "        val_prec = precision_score(y_val, y_val_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        test_prec = precision_score(y_test, y_test_pred)\n",
    "        # Save the scores to the model_scores dictionary\n",
    "        model_scores[name] = {\"validation_accuracy\": val_acc,\n",
    "                              \"validation_precision\": val_prec,\n",
    "                              \"test_accuracy\": test_acc,\n",
    "                              \"test_precision\": test_prec}\n",
    "        # Print the model's results on a new line\n",
    "        print(\"\\n\" + name)\n",
    "        print(model_scores[name])\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b43d78-0549-48a3-88a3-d1f8cf5d3622",
   "metadata": {},
   "source": [
    "This code defines a dictionary containing several machine learning models, including `Logistic Regression, AdaBoost Classifier, Gradient Boosting Classifier,` and `Random Forest`. Then, a function named `\"fit_and_score\"` is defined to fit and score these models on training, validation, and testing data. The function takes as input the models, training, validation, and testing data, and returns a dictionary of model scores that include validation and test accuracy and precision scores.\n",
    "\n",
    "The function loops through each model and fits it on the training data, then makes predictions on the validation and testing data. It calculates accuracy and precision scores on both the validation and test data, and saves these scores to a dictionary called \"model_scores\". The function then prints the results for each model and returns the \"model_scores\" dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a9c7c8-196f-4260-9c70-6b99396feadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "{'validation_accuracy': 0.7195714285714285, 'validation_precision': 0.7410451232749263, 'test_accuracy': 0.7200714285714286, 'test_precision': 0.7406254862299674}\n",
      "\n",
      "Adaboost Classifier\n",
      "{'validation_accuracy': 0.7338571428571429, 'validation_precision': 0.7748795480976907, 'test_accuracy': 0.7345, 'test_precision': 0.7738075452883497}\n",
      "\n",
      "Gradientboost Classifier\n",
      "{'validation_accuracy': 0.7366428571428572, 'validation_precision': 0.7543299908842297, 'test_accuracy': 0.7383571428571428, 'test_precision': 0.7537505682679194}\n",
      "\n",
      "Random Forest\n",
      "{'validation_accuracy': 0.7141428571428572, 'validation_precision': 0.7186733958183129, 'test_accuracy': 0.7107857142857142, 'test_precision': 0.7128286165780778}\n"
     ]
    }
   ],
   "source": [
    "# Call the fit_and_score function and print the results\n",
    "model_scores = fit_and_score(models, X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f79ce79-282c-4e2d-b2a8-7605ad1b1f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
